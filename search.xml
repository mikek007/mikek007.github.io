<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>NCRF</title>
    <url>/2022/02/10/NCRF/</url>
    <content><![CDATA[<h1 id="Noise-cancelling-repeat-finder-学习笔记"><a href="#Noise-cancelling-repeat-finder-学习笔记" class="headerlink" title="Noise-cancelling repeat finder 学习笔记"></a><a href="https://academic.oup.com/bioinformatics/article/35/22/4809/5530597?login=true">Noise-cancelling repeat finder</a> 学习笔记</h1><h2 id="文章背景"><a href="#文章背景" class="headerlink" title="文章背景"></a>文章背景</h2><p>在人类基因组中，<strong>长的串联重复的序列</strong>(long tandem repeat) 扮演着极其重要的角色。例如：TTAGGG 这段序列的串联重复对于保护着丝粒有关，AATGG 这段序列与热休克反应有关联等等。但是，当前缺少捕获这种长的TR序列的有效技术。之前出现过TRF软件对能够串联重复序列进行搜索，之后会写一篇笔记记录学习。  </p>
<span id="more"></span>
<p>在三代测序的超长read的加持下，对于tr序列的研究也可以更进一步，毕竟在短read的条件下，在串联重复区域很难判断overlap和repeat。前文提到的TRF由于没有考虑三代数据插入缺失率不相等的特点（本身就不是针对三代数据开发的），在三代环境下就没那么好用了。并且三代数据本身的高错误率也是面临的一大挑战。</p>
<h2 id="方法步骤"><a href="#方法步骤" class="headerlink" title="方法步骤"></a>方法步骤</h2><p><strong>目标</strong>：找到一段特定基序与一段给定DNA序列的比对结果。<br><strong>具体步骤</strong>：NCRF整体看是一种改进的smith-waterman算法。输入是repeat modtif（可以理解为基序列）的列表和一段DNA序列的集合。输出是一段read的间隔表来表示这些motif的对应关系（这里可以理解成一种比对结果的形式）。并最终会生成表格形式方便其他软件的导入。程序分为两个部分，C语言部分和python部分。C语言部分负责接入输入，并进行比对（read与motif之间），删除噪音非常大的比对结果，过，最终输出符合用户设定的足够长和正确率足够高的比对。接下来这些输出直接接入python脚本程序，进一步筛选比对结果，将幸存下来的比对打包好输出。<br><strong>具体的分布步骤如下</strong>： </p>
<p><strong>1</strong>，<strong>Wraparound aligner</strong>，我叫它粗比对。这部分就是纯纯的加了仿射的空位罚分的S-W算法。它使用的动态规划矩阵的最基本的实现形式，行代表motif中的核苷酸，列代表sequence（或者说是输入的read）的核苷酸，并且由于三代测序中插入缺失有一定的偏向性，所以打分会取决于输入数据的插入缺失的偏向性（<strong>文中尚未给出具体的打分方程以及这一步的具体步骤，所以这一步具体是怎么实现的怎么打分的，我自己尚未知</strong>）。然后这一步的重点来了，<strong>NCRF对动态规划的递归进行了几点修改</strong>：  </p>
<ul>
<li><p>1a， <strong>动态规划中的match/substitution允许从motif的尾跳到他的开头</strong>。这一点很好理解，因为重复序列，motif在一条read上很可能有多个匹配位点，又因为是串联的，所以在一条序列上会有很多首位串联的片段。同样的，删除这个选项同样需要循环（因为是串联重复也有可能删除到首尾相接的地方嘛），删除到下一个位点的得分不会再提高的时候，就停止这种删除。这样最优路线就会像一个锯齿状的牙齿一样，每个锯齿都是一个副本。不懂的话个最简单的情况的图就明白了。  </p>
<p><img src="https://pic.imgdb.cn/item/6204f6462ab3f51d916599b8.png" alt="锯齿状" title="锯齿状">  </p>
</li>
<li><p>1b， <strong>不允许back to back的插入方式</strong>，即使插入的得分比新开口的得分要高，我的个人理解是不允许连续的插入缺失，因为在pacbio这种三代数据中，单个插入缺失比长插入缺失要频繁的多。（我个人不太认同这种处理方式，因为我所接触的数据两三个碱基的插入缺失也数量庞大）。 </p>
</li>
<li><p>1c，<strong>允许对齐的结束和开始在motif的任意位置</strong>。比如AATGG，可能找到一个匹配序列是GGAATGGAATGGAATGGAATGGA。</p>
</li>
<li><p>1d，<strong>当找到一个局部最优比对后，将这段删除，再重复比对的过程</strong>。（我个人感觉这个对于算法提升并不大，在三代数据中甚至拉高了运行时间）</p>
</li>
<li><p>*2<strong>，</strong>Bridge and Tails<strong>。首先介绍这两个关键词，</strong>非相关桥接<strong>（unrelated bridge）和</strong>非相关尾部**（unrelated tails）。  </p>
</li>
<li><p> 假设两段紧挨的比对片段得分为X和Y，他们中间一段片段由于错误率过高，得分为-Z。那么，如果X&gt;Z,Y&gt;Z。X+Y-Z&gt;X+Y会成立。即得分还会上升，那么Z这段所对应的片段就叫做 <strong>unrelated bridge</strong>  </p>
</li>
<li><p> 任意一个片段它包含一段假阳性的前缀和后缀的概率都是非零的。即这个片段往前或往后的一些错误（实际上）片段也可能导致得分增加。片段A后面跟着一个假阳性的尾巴B，那么B就被称为 unrelated tails。  </p>
</li>
</ul>
<p>文章给出的解决方法也很简单，就是删除包含不匹配的或者插入缺失的部分。具体步骤就是通过计算一个片段的错误（错配，插入缺失）和全局的所有（匹配，错配，插入缺失）的比值。如果这个比值小于一个阈值，那么这个片段就是<strong>error clump</strong>。前缀后缀同样通过此种操作来判定。使用1999年zhang的算法（未找到参考文献不知道具体实施过程）去识别清除clump。删除后一个比对会变成两个或者多个，不满足用户长度要求的新生成的比对会被丢掉。剩下的比对将会被输出出来。需要注意的是，进行clump的移除并不会一处非相关尾部。而是假阳性的clump被移除掉后，剩下的非相关尾部会很短（因为中间部分假阳性的被移除了），后面会包含那一段很小的错误率很高的尾巴，这个尾巴会因为长度很短不满足用户条件被舍弃。 </p>
<p><strong>3</strong>，<strong>Consensus filting</strong>。这个中文应该叫一致性过滤。这一步只要是将上一步的比对结果进行整理，去掉有重叠的比对结果。因为一段序列可能包含好多不同的串联重复，比如一段序列可能既有ATAT的串联重复，又能看成是CGCG的串联重复（现实肯定是相近序列差别不会那么大）。NCRF将会从输出的比对结果中，提取其中占主导因素的motif，如果他们和输入的motif相同则通过过滤器，不通则不能通过。（作者认为如果要想得到完美的结果那么就希望我们得到的比对序列中，输入的motif比任何其他的序列排列都更加紧密、一致性序列应该和输入的motif相同）。具体的实现方法是通过将比对结果按motif一个个对齐好，每个位置取出现频率最高的字符，如果最终和输入一样，则通过过滤器。另外说一句这一步骤开始作者是用python写的。</p>
<p><strong>4</strong>，<strong>Scorinng parameters</strong>。直译就是评分参数。事实上结果在上一步就已经出来了，这个部分主要内容就是如何确定打分的参数。作者在这里建立了不同数据集的模拟数据，通过分析tr，tn等来优化参数。模拟数据的建立方式是先通过模拟1000个AATGG的完美串联重复的read，read长度服从正态分布（μ=2500，σ=1667），删掉长度在500以下的（太小），再在串联处，添加平均长度为500bp的随机DNA序列。细节可以参考文献附录，这里不作详细描述。</p>
<p><strong>5</strong>， <strong>Overlapping alignments</strong>，这里是程序处理的最后一个细节，就是在第三步程序输出一个最佳匹配的集合时，NCRF最终会选取一个alignmennt相互之间不包含overlap的最大子集，将这个子集作为结果输出。文中没给出具体的寻找方法，但已知相对位置的情况下这一步实现其实并不难，详细步骤对应代码中的 NCRP_overlaps.py。</p>
<h2 id="结果分析与展望"><a href="#结果分析与展望" class="headerlink" title="结果分析与展望"></a>结果分析与展望</h2><p>结果话不多说放两张图，一张是和其它软件结果的比对，主要是衡量true positive rete（TPR) 和false discovery rate（FDR)。另一张图是在真实数据上的表现并没有对比，主要是展示找到的重复的长度。<br><img src="https://pic.imgdb.cn/item/6205be8c2ab3f51d91017b0b.png" alt="table" title="table">  </p>
<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>仅供本人学习笔记使用，记下笔记网站备份一下。均为个人理解，不一定对，但可以当参考。</p>
]]></content>
      <categories>
        <category>Aligner</category>
      </categories>
      <tags>
        <tag>Aligner</tag>
      </tags>
  </entry>
  <entry>
    <title>hello world</title>
    <url>/2022/01/17/hello-world/</url>
    <content><![CDATA[<p>hello world！<br>测试一下自己的个人博客，以后在这里分享生物信息算法原理及软件设计方面的心得！！！</p>
]]></content>
      <categories>
        <category>Testing</category>
      </categories>
      <tags>
        <tag>testing</tag>
      </tags>
  </entry>
</search>
